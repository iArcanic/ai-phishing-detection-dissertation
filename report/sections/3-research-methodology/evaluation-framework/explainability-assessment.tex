% ai-phishing-detection-dissertation/report/sections/3-research-methodology/evaluation-framework/explainability-assessment.tex

\subsubsection*{Explainability assessment}
The explainability of the Random Forest and DistilBERT models were evaluated via a qualitative analysis of the explanations generated by the LIME and SHAP methods.

\begin{itemize}
  \item \textbf{Qualitative analysis of XAI outputs}:
  \begin{itemize}
    \item \textbf{For Random Forest (SHAP)}: SHAP was employed for this model, and the analysis involved:
    \begin{itemize}
      \item Identify TF-IDF features (terms or n-grams) by reviewing SHAP summary plots that impacted model predictions the most, on a global scale.
      \item Examine local explanations via waterfall or force plots for individual email instances in an understanding of how specific text components influenced the model's classification, considering the feature's plausibility and practicality.
    \end{itemize}
  \item \textbf{DistilBERT (LIME)}: LIME was employed for this model to generate word-level explanations for each individual prediction. The analysis mainly focussed on:
  \begin{itemize}
    \item Words highlighted by LIME are reviewed, deciding whether it contributes positively or negatively to the model's prediction.
    \item Assessing whether the highlighted words are relevant to the specific email instance being examined, as a means to understand the rationale behind the model's decision.
  \end{itemize}
  \item \textbf{User feedback on explanations}:
  \begin{itemize}
    \item A small group of users (3-5) were asked to review the generated explanations from both models. The aim was to gather qualitative feedback on the clarity, usefulness, and trustworthiness of the explanations.
    \item Participants were presented with selected SHAP explanations from the Random Forest model and LIME explanations from the DistilBERT model, along with the relevant individual email instances.
    \item Open-ended questions were posed to understand what aspects of the explanations clarified the model's decision-making process and whether they found the explanations helpful, particularly noting if it increased their trust in an AI-powered system.
  \end{itemize}
\end{itemize}
