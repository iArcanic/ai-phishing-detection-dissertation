% ai-phishing-detection-dissertation/report/sections/3-research-methodology/model-development/introduction.tex

Taking the preprocessed data that gives a neat, curated feature space, this section will describe the practical design and implementation of an AI phishing detection system that is integrated with XAI explainability methods. Such a setup addresses \hyperref[research-gap-1]{\uline{\textbf{Research Gap 1}}} (performance vs interpretability trade-offs) and \hyperref[research-gap-3]{\uline{\textbf{Research Gap 3}}} (lack of standardised framework for XAI evaluation).\newline

\noindent The model approach took two distinct machine learning models for the task of phishing detection: a traditional ensemble, Random Forest Model, and a transformer-based deep learning model, DistilBERT. The aim is to evaluate and compare their performance with one another, exploring how effective they are in terms of their explainability.\newline

\noindent A methodology like so allows to bridge the gap between traditionally black-boxed AI phishing detection models and more white-box interpretable models, meeting \hyperref[objective-2]{\uline{\textbf{Objective 2}}} whilst simultaneously reaching the defined user-centric goals (\hyperref[objective-4]{\uline{\textbf{Objective 4}}}).
