% ai-phishing-detection-dissertation/report/sections/3-research-methodology/model-development/security-specific-adaptations.tex

\subsubsection*{Security-specific adaptations}
It is important to secure the model, and implement the necessary defences against typical evasion techniques that attackers commonly use. This should not in any form impact the explainability methods being integrated into the model. Methods are drawn from \cite{kapoor2024comparative} and \cite{atlam2022business}, with XAI compatability in mind.\newline

\noindent Adversarial attacks, through text manipulation, are the main tactics attackers attempt, in a means to bypass phishing filters:

\begin{itemize}
  \item \textbf{Input perturbation defense}:
  \begin{itemize}
    \item \textit{Text attacks}: Training data is augmented with:
    \begin{itemize}
      \item Synonym swaps, like "urgent" $\Rightarrow$ "immediate" \citep{greco2023explaining}.
      \item Homoglyph replacements, such as "Paypal" $\Rightarrow$ "paypal".
      \item Case randomisation, i.e. "SECURE" $\Rightarrow$ "SeCuRe".
    \end{itemize}
    \item \textit{URL attacks}: Generates adversarial URLs through:
    \begin{itemize}
      \item Subdomain spoofing, e.g., "login.bank.com" $\Rightarrow$ "bank.com.login".
      \item URLs can be shortened with redirect chains.
    \end{itemize}
  \end{itemize}
  \item \textbf{Explanation consistency checks}:
  \begin{itemize}
    \item Outputs from SHAP/LIME should be closely watched for variance under such attacks (target $<8\%$ deviation).
    \item If explanations are unstable, then the predictions behind them should automatically be rejected.
  \end{itemize}
\end{itemize}

\noindent Dynamic thresholding can be applied to set adaptive boundaries that change in real time when needed:

\begin{itemize}
  \item \textbf{Risk-adaptive classification}:
  \begin{itemize}
    \item Decisions should be adjusted on fine-tune thresholds, which are bsed upon:
    \begin{itemize}
      \item Feature risk scores, for e.g., a mismatched domain adding to the overall risk score.
      \item Have a time context, meaning a higher sensitivity during prime attack hours \citep{vishwanath2011people}.
    \end{itemize}
    \item The threshold should take the following ranges:
    \begin{equation}
      T = \begin{cases}
        0.7 & \text{(Low-risk features)} \\
        0.4 & \text{(High-risk features)}
      \end{cases}
    \end{equation}
  \end{itemize}
  \item \textbf{Fallback mechanism}:
  \begin{itemize}
    \item If XAI explanations fail to properly highlight suspicious features:
    \begin{itemize}
      \item Human review should be integrated as a backup.
      \item Metadata and other according information from a failed explanation should be saved for subsequent analysis.
    \end{itemize}
  \end{itemize}
\end{itemize}

\noindent The model's explanations should respect the user's privacy along with compliance laws like GDPR. In practicality, this means measures like redacting personal data (email address/names) from SHAP outputs or hashing URL parameters for LIME displays. Differential privacy can be implemented for attention weights ($\epsilon=0.5$) \citep{hanif2021survey}.
