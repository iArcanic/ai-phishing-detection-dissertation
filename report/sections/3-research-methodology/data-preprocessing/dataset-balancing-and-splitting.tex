% ai-phishing-detection-dissertation/report/sections/3-research-methodology/data-preprocessing/dataset-balancing-and-splitting.tex

\subsubsection*{Training data and assembly splitting}
The primary training data, consisting of the Enron and CEAS 2008 datasets, were combined to form a corpus of legitimate ("ham") emails from Enron and phishing ("spam") from CEAS 2008. The total size of the corpus resulted in 40,000 emails, with a reasonable balance between ham and phishing classes (1:1 ratio almost). Oversampling techniques like SMOTE were not necessarily required in terms of class balancing for the initial training process. SMOTE was definitely considered as a viable option to balance classes due to insufficient data.\newline

\noindent The combined corpus was then split into three distinct sets, those being: a training set (15\%), a validation set (15\%), and a internal test set (15\%). Such a split was possible with \texttt{scikit-learn}'s "\texttt{train\_test\_split}" function, utilising stratification methods based on the email labels. This was to ensure a consistent class proportion across all the sets.
