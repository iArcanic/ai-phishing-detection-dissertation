% ai-phishing-detection-dissertation/report/sections/2-literature-review/justification-for-this-study/justification-1.tex

\subsubsection*{1. Bridging the interpretability-performance divide}
As explored, existing models have been seen to achieve high accuracies such as 99.7\% in a study by \cite{do2024integrated}. But they are hindered by their black-boxed nature, limiting trust and practical deployability \citep{atlam2022business}. This study directory addresses \hyperref[research-gap-1]{\uline{\textbf{Research Gap 1}}} by:

\begin{itemize}
  \item Implementing XAI techniques, like SHAP, LIME, EBM, or attention mechanisms, on state-of-the-art models such as transformers or random forests in an attempt to preserve model accuracy (\hyperref[objective-2]{\uline{\textbf{Objective 2}}}).
  \item The trade-offs between both explainability and performance should be quantified, meeting \hyperref[sub-research-q4]{\uline{\textbf{Sub Research Question 4}}}. There is a need for a balanced solution by \cite{alzahrani2024explainable}.
\end{itemize}
