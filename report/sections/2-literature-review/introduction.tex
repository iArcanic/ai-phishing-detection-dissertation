\subsection*{Introduction}

Since the internet has become a vital part in the lives of all, it has given a sudden exponential rise in the use of technology. A survey conducted by the Global Digital Population Survey Report (GDP) noted that in 2023, there was an approximate estimate of nearly 5.3 billion users of the internet \citep{kemp2022digital}. A significant rise was seen from 2019 onwards, due to the pandemic, meaning many traditional offline services were forced to be converted to their online counterpart. This connectivity has led to many individuals sharing out their personal data, both intentionally and unintentionally, making it the target for cybercriminals to exploit, with one such particular method is using a social engineering tactic known as phishing \citep{zahra2022detecting}, that utilise further methods such as content personalisation and psychologically manipulating the victim \citep{jagatic2007social}. It can expand across to many online areas, but this project's scope focusses specifically on email communication.\newline 

\noindent Over the past years in particular, the Anti-Phishing Working Group (APWG) have reported a significant increase in phishing attacks in the recent years (\citeauthor{chirra2020ai}, \citeyear{chirra2020ai}; \citeauthor{syed2018ensuring}. \citeyear{syed2018ensuring}). This gives rise to AI-driven phishing detection systems offering promise and leveraging the power of machine learning (ML) and deep learning models with the task of classifying emails as either legitimate or phishing. It is important to note that interpreting these AI models is still difficult, making it challenging to trust in decisions they make, raising concerns about trust, regulatory compliance, and model robustness in settings such as finance and healthcare, where the decision-making processes must be auditable and explainable \citep{jain2022survey}.\newline

\noindent Explainable AI (XAI) is a means to address these interpretability challenges with AI phishing detection. Techniques like SHAP (SHapley Additive Explanations) and LIME (Local Interpretable Model-agnostic Explanations) can disect the model's decisions, with the aim of helping users understand why a particular email is considered as phishing \citep{lundberg2017unified}. However, research on applying XAI techniques to supplement phishing detection systems is currently limited, with most studies prioritising accuracy rather than interpretability \citep{ribeiro2016model}.\newline

\noindent This literature review therefore explores AI phishing detection techniques being utilised today, their current limitations, and how XAI can be relevant to these systems, with references to existing studies. The review naturally gave rise to some identified research gaps, which lead onto a justification as to why this project was needed. It sets the stage for subsequent the development of an XAI-enhanced phishing detection model.

