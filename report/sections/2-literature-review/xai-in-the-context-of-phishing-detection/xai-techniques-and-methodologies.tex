% ai-phishing-detection-dissertation/report/sections/2-literature-review/xai-in-the-context-of-phishing-detection/xai-techniques-and-methodologies.tex

\subsubsection*{XAI techniques and methodologies}
There are many ways this can be achieved, and this moves the literature review to specific XAI techniques that can be utilised and practically implemented into AI-powered systems, such as SHAP and LIME as a way to offer insights \citep{shendkar2024enhancing} by providing both global and localised explanations, respectively \citep{palaniappan2020malicious}. There is also an additional higher level explainability technique, EBM, referred to by \cite{hernandes2021phishing}, that is a complete white-boxed approach that aims to construct a predictive model that is already inherently explainable by design and does not require additional interpretability tools post processing \citep{greco2023explaining}. Comparing this with LIME, it builds an interpretation based upon existing black-boxed models' outcomes. Both these techniques provide local and global explanations and are model-agnostic, i.e. they can work with any model or classifier that's ML-based \citep{anderson2015polymorphic}. \cite{greco2023explaining} also dives deeper into the different between local and global explanations, adding onto previous understanding. The author mentione that local explanations consist of a "feature importance vector" which is a quantifiable value that shows how much that specific feature contributed to the outcome. This is contrasting to global explanations, as they require both the entire model and its processing mechanisms.
