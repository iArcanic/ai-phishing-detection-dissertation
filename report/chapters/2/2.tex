\section{Literature review}

\subsection*{Introduction}
Phishing attacks remain one of the most prominent attack methods faced by cybersecurity, meaning AI-based detection measures become increasingly essential given that attackers are continiously refining their techniques in attempts to bypass traditional detection systems. AI-driven phishing detection systems offer promise, leveraging the power of machine learning (ML) and deep learning models with the task of classifying emails as either legitimate or phishing. It is important to note that interpreting these AI models is still difficult, making it challenging to trust in decisions they make, raising concerns about trust, regulatory compliance, and model robustness in settings such as finance and healthcare, where the decision-making processes must be auditable and explainable.\newline

\noindent Explainable AI (XAI) is a means to address these interpretability challenges with AI phishing detection. Techniques like SHAP (SHapley Additive Explanations) and LIME (Local Interpretable Model-agnostic Explanations) can disect the model's decisions, with the aim of helping users understand why a particular email is considered as phishing \citep{lundberg2017unified}. However, research on applying XAI techniques to supplement phishing detection systems is currently limited, with most studies prioritising accuracy rather than interpretability.\newline

\noindent This literature review therefore explores any existing AI phishing detection techniques, their current limitations, and how XAI can be implemented to improve transparency and confidence in these systems, suitable for a real-time environment. In addition, key research gaps are identified, such as the trade-offs between model accuracy and interpretability. It sets the stage for subsequent the development of an XAI-enhanced phishing detection model.

\newpage

\subsection*{AI-based phishing detection approaches}
This section starts with providing an overview into how AI and ML are utilised in detecting phishing attacks. In essence, whilst traditional rule-based approaches are effective for phishing emails with static patterns, they struggle to keep up with adaptable attacks. This naturally gives rise into exploring with combination of ML, deep learning, and hybrid models to improve detection accuracy.

\subsubsection*{Traditional ML approaches}
Traditional phushing detection models use regular ML algorithms that are trained on a large dataset consisting of both legitimate and phishing emails. To dive deeper, these models are trained on email headers, embedded email URLs, sender information, and message content. Extracting predefined features and feeding them into statistical-based classifiers to differentiate between email types \citep{chandrasekaran2006phoney}.

\paragraph{Common ML algorithms for phishing detection}
\begin{itemize}
    \item \textbf{Logistic Regression (LR)}
    \begin{itemize}
        \item A very simple ML classifier, mapping linear relationships to determine phishing likelihood depending upon weighted feature importance.
        \item It is simple to implement, being fast yet also interpretable.
        \item However, it can only linearly seperate data.
    \end{itemize}
    \item \textbf{Decision Trees (DT)}
    \begin{itemize}
        \item Classifies emails based on a set of rules that follow a hierarachy, i.e. if the email contains a suspicious URL, clasify it as phishing.
        \item Human-readable rules can be defined, making it interpretable.
        \item It is limited by its liability to overfitting.
    \end{itemize}
    \item \textbf{Random Forest (RF)}
    \begin{itemize}
        \item A combination of multiple decision trees to refine classification accuracy.
        \item More accurate than just a singular decision tree, and handles data with large noise.
        \item More difficult to understand than individual decision trees.
    \end{itemize}
    \item \textbf{Support Vector Machines (SVMs)}
    \begin{itemize}
        \item Finding an optimised decision boundary (or hyperplane) between phishing and legitimate emails.
        \item It works well in high-dimensional spaces.
        \item Struggles with large datasets due to its demand for computational resources.
    \end{itemize}
\end{itemize}

\paragraph{Limitations of traditional ML approaches}
Traditional ML approaches are quite limited. They require manual feature selection from the dataset, for example patterns in phishing URLs or domain reputation. They are also hard to adapt when detecting any new phishing attacks encountered. On more complex data, it exhibits lower accuracy, especially phishing emails that utilise social engineering methods.

\subsubsection*{Deep learning and NLP approaches}
Limitations of traditional, feature-based ML models for phishing detection can be overcome with deep learning (DL) and Natural Language Processing (NLP) techniques. These models themselves learn patterns in email text, links and metadata without manual feature selection.

\paragraph{Common deep learning and NLP-based approaches}
\begin{itemize}
    \item \textbf{Recurrent Neural Networks (RNNs) \& Long Short-Term Memory (LSTMs)}
    \begin{itemize}
        \item Used for analysing email text to detect intent of phishing, e.g. urgency such as "immediate action required" or "your account is compromised".
        \item Mainly effective for textual patterns.
        \item Training process is very slow, and it struggles with longer texts.
    \end{itemize}
    \item \textbf{Convolutional Neural Networks (CNNs)}
    \begin{itemize}
        \item Suitable for phishing URL classification and visual phishing attacks (i.e. images and/or fake websites).
        \item Works very well for image-based phishing detections.
        \item Performance declines for textual analysis.
    \end{itemize}
    \item \textbf{Transformer-based models (BERT, RoBERTa, GPT)}
    \begin{itemize}
        \item Pre-trained NLP models, such as BERT (Bidirectional Encoder Representations from Transformers) use semantic means to classify phishing emails, e.g. PhishBERT, a fine-tuned AI model speficially for phishing detection, outperforming traditional NLP solutions.
        \item Boasts a very high accuracy.
        \item It is very hard to interpret and computationally expensive.
    \end{itemize}
\end{itemize}

\paragraph{Limitations of deep learning approaches}
Most deep learning models are black-boxed, meaning it is hard for humans to understand. Not to mention, they require significant resources to be trained and tested. Attackers can also find ways to bypass these models via adversarial attacks, as it is susceptible to email content that is intentionally altered to evade detection.

\subsubsection*{Hybrid models and ensemble learning}
Researchers have proposed a combination of the aforementioned approaches in the form of hybrid models, that take into account both traditional and deep learning implementations.

\paragraph{Hybrid approach examples}
\begin{itemize}
    \item \textbf{ML and NLP models}
    \begin{itemize}
        \item ML models such as SVM and Random Forest can be combined with TF-IDF (Term Frequency-Inverse Document Frequency) for feature extraction.
    \end{itemize}
    \item \textbf{Ensemble learning}
    \begin{itemize}
        \item Multiple classifiers (both ML and DL) are used and their predictions are accumulated for an improved accuracy, e.g. majority voting ensemble.
        \item Results in a higher accuracy then just singular models.
        \item Complex to interpret and harder to deploy practically.
    \end{itemize}
\end{itemize}

\paragraph{Limitations of hybrid models}
There is a clear trade-off between performance and complexity. The more complex the model, the better the performance and as a result, the requirement for more resources. Additionally, the layers of complexity make it harder to interpret.

\subsubsection*{Summary}
AI-based phishing detection systems have evolved from just traditional ML models to unique deep learning and hybrid approaches. Although this improves their accuracy, subsequent challenges are introduced, such as interpretability, demand for more computational resources, and vulnerability to adversarial attack manipulation. XAI techniques can be a way to address some of these challenges, especially relating to interpretability, by ensuring transparency and trust.\newline

\noindent The next section will dive deeper into limitaitons of current phishing detection systems, leading onto why explainability is an important factor for an optimal phishing detection solution.

\newpage

\subsection*{Limitations of current AI-based approaches}
Although AI-driven phishing detections solutions have greatly improved cybersecurity efforts, but the models used also suffer from many limitations that make it hard to deploy them in real-world settings. Some of these challenges have been briefly explored in the previous section, but these include the black-boxed nature of some models (deep learning in particular), high false positive and negative rates, limitations of the dataset, and vulnerability to semantic-based attacks. This section delves into more detail on these issues.

\subsubsection*{Black-box nature of AI models}
A large proportion of existing AI phishing detection models, specifically deep learning-based systems, are black-boxed, meaning that their decision making processes are obscured from the user. This is problematic for long-term system usage as interpretability isn't taken into much consideration, and affects:

\begin{itemize}
    \item Users and security analysts, as they cannot establish why an email is flagged as phishing.
    \item Regulatory frameworks, such as GDPR, need AI decisions to be interpretable.
    \item AI models need to be trustworthy if organisations need to justify results made by these systems.
\end{itemize}

\noindent Taking the transformer-based models (e.g. BERT, RoBERTa) as an example, they make predictions based on millions of parameters regardless of their high accuracy. It is therefore difficult to decide which features were responsible for the final classification decision.\newline

\noindent An exemplar scenario can be considered. A security team using a deep learning phishing detection model, achieving 95\% accuracy without much reasoning. It's tough to determine whether the decision-making processes were biased by actual revelvant security features or external noise.\newline

\noindent This is important as the inability to understand AI decisions inhibit it from being implemented in sensitive sectors -- financial, healthcare, and legal -- where explainability is part of a compliance requirement (\textit{Regulation EU 2016/679}).

\subsubsection*{Accuracy vs. explainability trade-off}
There is a clear trade-off between accuracy and explainability in phishing detection models. Highly accurate models taper off in their interpretability, but on the other hand, more interpretable models suffer in accuracy. The challenge here is striking a balance and achieving a model that is both reasonable in its accuracy and interpretability.\newline

\noindent For example, a BERT model with a 98\% accuracy but is completely black-boxed. A random forest model with a 90\% accuracy is less black-boxed and it moderately interpretable. Finally, a decision tree model has the least accuracy with 85\% but is the most interpretable. This is an example of the relationship between better performance compared with interpretability.\newline

\noindent Again, organisations may hesitate to deploy AI models if decisions cannot be verified with proper evidence. In some cases even, a more interpretable model with less accuracy is preferable in high-risk sectors to inspire user confidence.

\subsubsection*{False positives and false negatives}
Any AI-driven systems are prone to generating false positives, i.e. legitimate emails incorrectly flagged as phishing, and false negatives, i.e. phishing emails being classed as legitimate. Each have their own cases.

\paragraph{False positives (FPs) -- legitimate emails flagged as phishing}
\begin{itemize}
    \item If important business emails are blocked, it can distrupt typical company operations.
    \item Security analysts can suffer from alert fatigue, and lead to mistaking phishing emails as legitimate in the long-term.
    \item An example is an AI model incorrectly flagging a legitimate email from an unfamliar third party verified by the organisation as phishing.
\end{itemize}

\paragraph{False negatives (FNs) -- phishing emails classed as legitimate}
\begin{itemize}
    \item More dangerous as missed phshing emails can potentially lead to security breaches.
    \item Attacks can exploit this and evade detection by making minor textual changes.
    \item An example might be a phishing email micking a legitimate Microsoft security alert, and detection is bypassed by a small spelling change.
\end{itemize}

\noindent A comparison of multiple phishing detection solutions showed that high-accuracy models can falter in real-world sceenarios. To take a particular example, CNN-based models achieved 96\% accuracy but had a 6\% false negative rate. It goes to show that only a single successful phishing email can result in a major data breach. Security teams must therefore carefully fine-tune AI models to minimise false negatives and have false positives be managable in a practical sense.

\subsubsection*{Dataset challenges}
A phishing detection model's accuracy depends largely on the datasets they were trained on, especially the quality and diversity of the data. But this gives rise to many issues.

\paragraph{Lack of real-world phishing samples}
A lot of existing datasets consist of phishing emails that are outdated and are not reflective of modern techniques. It is common knowledge that attackers contantly evolve, so any models trained on old datasets have a higher chance of failing to detect new methods. This was evident in a 2019 study, which found that a phishing detection model tained on a 2016 dataset has a 30\% lower accuracy when faced with unseen phishing emails utilising new techniques.

\paragraph{Imbalanced datasets}
Most datasets contain much more legitimate emails when compared to phishing emails, such a 95\%-5\% split. A model can therefore be heavily biased and classify many emails as legitimate -- a high false negative rate. Using techniques such as SMOTE (Synthetic Minority Over Sampling) can lead to a more balanced dataset by generating synthetic samples for lesser classes. Rare phishing patterns can be the focus of some models, i.e. anomaly detection models, rather than strict classification.\newline

\noindent An AI model, although being highly accurate, if trained on an imbalanced dataset it can skew results and have a profound failure in real-world contexts. For practicality and effictiveness, automated periodic dataset updates should take place alongside real-time deployment.

\subsubsection*{Adversarial attack vulerabilities}
As mentioned before, AI models are susceptible to carefully crafted phishing emails with the objective of evading detection. This is classed as an adversarial attack.\newline

\noindent Adversarial attacks work by making small modifications to textual components of the phishing email, including URLs, or metadata to circumvent filters proposed by the AI model. For example, homoglyph attacks are commonly used, i.e. using "m\'{i}crosoft.com" instead of "microsoft.com" (note the difference in the letter "i"). It can be showcased by this exemplar study, by which showed that even minor modifications to a phishing email's wording can completely fool deep learning models and hence invoking a false negative.\newline

\noindent There are clear mitigations strategies to address this attack type. Models can specifically be trained on a dataset of purposely manipulated phishing emails, so they can learn how to classifiy these emails accordingly. Furthermore, by using a hybrid AI and rule-based approached accompanied by static phishing indicators can prove to be useful.\newline

\noindent Since phishing attackers are constantly devising new ways to bypass detection systems, it is of utmost importance to continiously make these systems aware on manipulation methods.

\subsubsection*{Summary}
It can be commonly agreed that AI significantly improves phishing detection, however, the current models explored faced the outlined challenges that include interpretability, dataset limitations, adversarial attacks, and false positives/negatives -- limitations which can be addressed by Explainable AI (XAI) with the overarching goal of improving trust, transparency, and real-world versatile deployment.\newline

\noindent In the next section, XAI and subsequently, its techniques, will be examined as to how they can confront the identified challenges.

\newpage

\subsection*{Introduction to Explainable AI (XAI)}
Previous sections discussed how most AI-based phishing detection models are often black-boxed systems -- their decision making processes are hard to interpret and understand. This lack of transparency makes it difficult for security analysts to validate a model's predictions, and asosciated issues about trust and regulatory compliance are raised. This is where Explainable AI (XAI) can work to meet these concerns by providing perspective into an emails classification as either phishing or legitimate.\newline

\noindent This section therefore dives into what XAI is, its importance in phishing detection, and existing XAI techniques that can be integrated to improve AI phishing classfiers.

\subsubsection*{What is Explainable AI?}
When discussing XAI, it refers to the different methods and techniques that allow for decisions made by AI models to be understandable to humans. Dissimilar to typical black-boxed AI models, XAI gives results that have human-readable justifications for its processes.

\paragraph{Key goals of XAI}
\begin{itemize}
    \item \textbf{Transparency}
    \begin{itemize}
        \item Insight into how AI models make decisions and come to a final result.
    \end{itemize}
    \item \textbf{Trustworthiness}
    \begin{itemize}
        \item Give the user more confidence in AI-generated outcomes.
    \end{itemize}
    \item \textbf{Regulatory compliance}
    \begin{itemize}
        \item AI decisions should align with regulatory frameworks such as GDPR (General Data Protection Regulation) and any other organisation-specific compliance.
    \end{itemize}
    \item \textbf{Debugging and bias detection}
    \begin{itemize}
        \item The explainability can aid in identifying errors and any skew in the decision making flow.
    \end{itemize}
\end{itemize}

\paragraph{Types of AI model explainability}
\begin{enumerate}
    \item \textbf{Global explainability}
    \begin{itemize}
        \item Give an overview into how the entire model functions.
        \item E.g. the importance of feature analysis in detection systems using the random forest algorithm.
    \end{itemize}
    \item \textbf{Local explainability}
    \begin{itemize}
        \item Focuses on the individual predictions made by the model rather than the whole.
        \item E.g. why an email is classed as phishing via SHAP or LIME.
    \end{itemize}
\end{enumerate}

\noindent XAI can help security analysts understand why a phishing email was detected, isolating irrelvant noise and features.

\subsubsection*{XAI's importance in phishing detection}
Eventhough it's understood that existing AI-based phishing detection models already achieve a high accuracy rate, they lack interpretability meaning they cannot be implemented in high-risk environments.

\paragraph{Key benefits of XAI}
\begin{enumerate}
    \item \textbf{Improves model trust and adoption}
    \begin{itemize}
        \item Before blocking emails, security teams need to verify their AI predictions.
        \item If an email is flagged as suspicious, XAI can show why and if the decision from the AI model is worth trusting.
    \end{itemize}
    \item \textbf{Helps security analysts identify false positives and false negatives}
    \begin{itemize}
        \item False positives can cause actual business emails to be blocked.
        \item False negatives means that phishing emails can bypass detection.
        \item XAI allows detection thresholds to be fine-tuned.
    \end{itemize}
    \item \textbf{Regulatory compliance (GDPR, AI ethics)}
    \begin{itemize}
        \item Certain regulations, such as GDPR (Article 22), require AI decisions to be explainable.
        \item Organisations that utilise AI systems for email filtering need processes to be transparent and auditable.
    \end{itemize}
\end{enumerate}

\noindent Using an example of a bank. If they were to use an AI-based phishing filter, explanations must be provided as to why certain emails were flagged, specifically if they influence the customer base or company higher-ups (\textit{Regulation EU 2016/679}).

\subsubsection*{XAI techniques in phishing detection}
There are many XAI techniques to supplement transparency within phishing detection models. Techniques such as SHAP, LIME, and other additional interpretable processes are briefly details.

\paragraph{SHAP (SHapley Additive Explanations)}
With SHAP, each feature (could be the email subject, sender address, or a URL) is assigned a Shapley value, as measure of its contibution towards the models final decision. It can provide both a global and local interpretation.\newline

\noindent Take the instance of a phishing detection model classifying an email as phishing. SHAP therefore reveals the presence of suspicious indicators, which might be words ("urgent" or "payment required") and perhaps an unknown IP address, that mainly contributed to the final decision.\newline

\noindent SHAP works well to provide explanations that are theoretically evidenced and fits in well with complex models such as deep learning. However, SHAP tends to be computationally expensive and hard for non-technical users to understand decision factors.

\paragraph{LIME (Local Interpretable Model-Agnostic Explanations)}
LIME intentionally malforms the input data to see how predictions change in real-time. The goal here is to create a simple interpretable model, e.g. with linear regression, to serve as an approximation to complicated AI decisions.\newline

\noindent If for example a classifier flags an email as phishing, LIME would highlight any factors that heavily influenced the final decision, such as a shortened URL or a phrase of urgency.\newline

\noindent The advantage of this is that LIME it model agnnostic, i.e. it works with any AI model algorithm. It is also much faster than SHAP. However, its limitation is that its much less accurate than SHAP and its output of explanations are likely to be unstable -- dependent on the data sampling tactics used.

\paragraph{Attention mechanisms in transformer models}
Transformer-based models, such as BERT or GPT, use attention measures to determine the words or phrases of importance when making a decision. Attention heatmaps are helpful in showing which parts of an email have the most contribution to a phishing classification.\newline

\noindent For example, a phishing detection model usilising BERT would highlight phrases such as of suspicion in a potential phishing email, such as persuading a user to click on specific links.\newline

\noindent Attention mechanisms can seamlessly integrate with NLP models and performs particularly well for longer email texts, keeping it consistent. But when compared to SHAP and LIME techniques, it falls short and is considered "opaque", i.e. there is still some black boxing.

\paragraph{Feature importance analysis in traditional machine learning}
For more simpler models like random forest or decision trees, the features importance can be examined to see which of the dataset's features most infleunced the final classification.\newline

\noindent Taking the example of a decision tree classifier, if it shows that "containes shortened URL" as the most important factor, this would be flagged as such.\newline

\noindent The advantages of this is its high interpretability, and works without much computational resources. Although it can work with deep learning models, it is less applicable and therefore not recommended -- suitable for more traditional ML models.

\paragraph{Comparing XAI methods for phishing detection}
It depends on the use case for whiever method to shine the best.\newline

\noindent Starting with SHAP, its boats high accurace, globally applicable to most models, and has local interpretability. However it is computationally expensive. It is best suited for deep larning models, such as BERT and CNNs. Next, LIME is fast and model independent, however, it is less stable with a higher chance of it giving inconsistent results. But it performs well for quick explanations, particularly in ML and NLP models. Attention mechanisms are already default for NLP models, however, they still lack full transparency. It performs well for transformer models such as BERT and GPT. And finally, feature importance is simple to understand, yet its limited to only traditional machine learning models. It works well with decision trees and random forest based classifiers.

\noindent If there is a requirement for a phishing detection model implemented upon a deep learning algorithm, SHAP would be the best pick. But if fast local explanations are needed instead, LIME serves as the best alternative. If using transformer based models, attention mechanisms is the most optimised here to provide valuable insights.

\subsubsection*{Summary}

\noindent The XAI techniques, SHAP, LIME, attention mechanisms, and feature importance, can all be employed to make AI-based phishing detection models more interpretable for transparency and inspire a sense of confidence in decisions being made. It is worth nothing that current research has not fully captured the trade-offs between interpretability and performance in the context of phishing detection.\newline

\noindent The next section explores the current research gaps identified in this field, to later on detailing how this dissertation will work to address them.

\newpage

\subsection*{Identified research gaps}
Whilst Explainable AI (XAI) has indeed gained usage and popularity in other domains, not limited to cybersecurity, its application to phishing detection is very infantile at this stage. From existing research, there is a primary focus on improving accuracy instead of transparency or explainability.

\subsubsection*{Lack of comparative studies}
The existing research in this space focuses on applying either SHAP of LIME individually, and there are not many studies that directly cross-compare different XAI techniques specifically for phishing email classification.

\paragraph{Why this matters}
Organisations, especially those in high-risk settings, that use AI-based phishing detection models need clear cut evidence (usually numerical) on which XAI method is most optimal for their use case. A lack of comparative studies can present a challenge for security teams in choosing the best interpretability technique.

\paragraph{Existing research limitations}
For each interpretability technique, the research is limited. With SHAP, its widely used for feature attribubtion, but is computationally expensive. LIME is faster but stable and more inconsistent. Transformer-based attention mechanisms do give some transparency, but are still blackboxed to an extent.

\paragraph{Opportunity}
The reserarch here in this project addresses this shortcoming, by comparing the different XAI techniques (SHAP, LIME, attention mechanisms, and feature important analysis) on phishing datasets to evaluate their performance in a real-time environment.

\subsubsection*{Interpretability vs. performance trade-off}
Models that are highly interpretable, like decision trees, often have a lower accuracy. Higher performing models such as BERT lack transparency. There are few studies that explore the extent to which model interpretability affects phishing classification accuracy.

\paragraph{Why this matters}
Eventhough a model might be highly interpretable, it is completely uneeded if it cannot detect phishing emails with a resonable accuracy. It is up to organisations to balance interpretability and accuracy if utilising AI-based phishing detection systems.

\paragraph{Existing research limitations}
Existing studies only focus on either accuracy or interpreteablity, but never both together. There is limited work on quantifying XAI usage on phishing detection.

\paragraph{Opportunity}
The research in this project will evaluate the trade-offs between both accuracy and interpreteablity using the various XAI techniques.

\subsubsection*{Real-world deployment challenges}
Research on existing AI phishing detection systems often rely on using static email datasets, but this is a problem since phishing emails are constantly evolving on a day-to-day basis. There is little to no research on the deployment of XAI supplemented models in a real-world setting.

\paragraph{Why this matters}
If AI models are trained on outdated phishing data, they can fail in detecting new, modern threats. Security teams therefore need real-time interpreteablity to understand new attack patterns so they can adapt their tools accordingly.

\paragraph{Existing research limitations}
Datasets, such as SpamAssassin and Enron, are liable to containing oudated phishing emails. Few studies explore the integration of real-world phishing emails from enterprise environments to train AI models upon.

\paragraph{Opportunity}
This project will therefore test XAI-enhanced phishing detection models in a dynamic environment, i.e. a dataset that dynamically updates.

\subsubsection*{Adversarial attacks on XAI models}
XAI models are suspect to manipulation by attacks to specifically evade detection. There is little research on how adversarial phishing emails bypass explainability techniques.

\paragraph{Why this matters}
Attacks can craft phishing emails to deliberately mislead XAI explanations and make them appear legitimate. A security model, although explainable, its vulnerability to adversarial makes it ineffective for actual usage.

\paragraph{Existing research limitations}
A few studies not how attackes manipulate XAI models in the context of phishing detecting. There aren't key guidlines or a rigid framework in how to defend against adversarial attacks for explainable phishing detection models.

\paragraph{Opportunity}
The research in this dissertation will analyse how XAI models can be tricked by adversarial attacks and suggest relevant defensive measures.

\subsubsection*{Summary}
Despite the numerous advancement in AI phishing detection systems, there are research gaps in comparing XAI techniques, real-world applications, adversarial robustness, and the interpreteablity vs accuracy trade-offs.\newline

\noindent The next section will address how this research practically aims to meet these research gaps, detailing a proposed methodology for implementing and evaluating an XAI phishing detection mdoel.

\newpage

\subsection*{Project's contribution in addressing research gaps}

\subsubsection*{Developing a transparent phishing model}

\subsubsection*{Comparing SHAP and LIME for phishing email classification}

\subsubsection*{Ensuring real-world applicability}
