\section{Literature review}

\subsection*{Introduction}
Phishing attacks remain one of the most prominent attack methods faced by cybersecurity, meaning AI-based detection measures become increasingly essential given that attackers are continiously refining their techniques in attempts to bypass traditional detection systems. AI-driven phishing detection systems offer promise, leveraging the power of machine learning (ML) and deep learning models with the task of classifying emails as either legitimate or phishing. It is important to note that interpreting these AI models is still difficult, making it challenging to trust in decisions they make, raising concerns about trust, regulatory compliance, and model robustness in settings such as finance and healthcare, where the decision-making processes must be auditable and explainable.\newline

\noindent Explainable AI (XAI) is a means to address these interpretability challenges with AI phishing detection. Techniques like SHAP (SHapley Additive Explanations) and LIME (Local Interpretable Model-agnostic Explanations) can disect the model's decisions, with the aim of helping users understand why a particular email is considered as phishing \citep{lundberg2017unified}. However, research on applying XAI techniques to supplement phishing detection systems is currently limited, with most studies prioritising accuracy rather than interpretability.\newline

\noindent This literature review therefore explores any existing AI phishing detection techniques, their current limitations, and how XAI can be implemented to improve transparency and confidence in these systems, suitable for a real-time environment. In addition, key research gaps are identified, such as the trade-offs between model accuracy and interpretability. It sets the stage for subsequent the development of an XAI-enhanced phishing detection model.

\newpage

\subsection*{AI-based phishing detection approaches}
This section starts with providing an overview into how AI and ML are utilised in detecting phishing attacks. In essence, whilst traditional rule-based approaches are effective for phishing emails with static patterns, they struggle to keep up with adaptable attacks. This naturally gives rise into exploring with combination of ML, deep learning, and hybrid models to improve detection accuracy.

\subsubsection*{Traditional ML approaches}
Traditional phushing detection models use regular ML algorithms that are trained on a large dataset consisting of both legitimate and phishing emails. To dive deeper, these models are trained on email headers, embedded email URLs, sender information, and message content. Extracting predefined features and feeding them into statistical-based classifiers to differentiate between email types \citep{chandrasekaran2006phoney}.

\paragraph{Common ML algorithms for phishing detection}
\begin{itemize}
    \item \textbf{Logistic Regression (LR)}
    \begin{itemize}
        \item A very simple ML classifier, mapping linear relationships to determine phishing likelihood depending upon weighted feature importance.
        \item It is simple to implement, being fast yet also interpretable.
        \item However, it can only linearly seperate data.
    \end{itemize}
    \item \textbf{Decision Trees (DT)}
    \begin{itemize}
        \item Classifies emails based on a set of rules that follow a hierarachy, i.e. if the email contains a suspicious URL, clasify it as phishing.
        \item Human-readable rules can be defined, making it interpretable.
        \item It is limited by its liability to overfitting.
    \end{itemize}
    \item \textbf{Random Forest (RF)}
    \begin{itemize}
        \item A combination of multiple decision trees to refine classification accuracy.
        \item More accurate than just a singular decision tree, and handles data with large noise.
        \item More difficult to understand than individual decision trees.
    \end{itemize}
    \item \textbf{Support Vector Machines (SVMs)}
    \begin{itemize}
        \item Finding an optimised decision boundary (or hyperplane) between phishing and legitimate emails.
        \item It works well in high-dimensional spaces.
        \item Struggles with large datasets due to its demand for computational resources.
    \end{itemize}
\end{itemize}

\paragraph{Limitations of traditional ML approaches}
Traditional ML approaches are quite limited. They require manual feature selection from the dataset, for example patterns in phishing URLs or domain reputation. They are also hard to adapt when detecting any new phishing attacks encountered. On more complex data, it exhibits lower accuracy, especially phishing emails that utilise social engineering methods.

\subsubsection*{Deep learning and NLP approaches}
Limitations of traditional, feature-based ML models for phishing detection can be overcome with deep learning (DL) and Natural Language Processing (NLP) techniques. These models themselves learn patterns in email text, links and metadata without manual feature selection.

\paragraph{Common deep learning and NLP-based approaches}
\begin{itemize}
    \item \textbf{Recurrent Neural Networks (RNNs) \& Long Short-Term Memory (LSTMs)}
    \begin{itemize}
        \item Used for analysing email text to detect intent of phishing, e.g. urgency such as "immediate action required" or "your account is compromised".
        \item Mainly effective for textual patterns.
        \item Training process is very slow, and it struggles with longer texts.
    \end{itemize}
    \item \textbf{Convolutional Neural Networks (CNNs)}
    \begin{itemize}
        \item Suitable for phishing URL classification and visual phishing attacks (i.e. images and/or fake websites).
        \item Works very well for image-based phishing detections.
        \item Performance declines for textual analysis.
    \end{itemize}
    \item \textbf{Transformer-based models (BERT, RoBERTa, GPT)}
    \begin{itemize}
        \item Pre-trained NLP models, such as BERT (Bidirectional Encoder Representations from Transformers) use semantic means to classify phishing emails, e.g. PhishBERT, a fine-tuned AI model speficially for phishing detection, outperforming traditional NLP solutions.
        \item Boasts a very high accuracy.
        \item It is very hard to interpret and computationally expensive.
    \end{itemize}
\end{itemize}

\paragraph{Limitations of deep learning approaches}
Most deep learning models are black-boxed, meaning it is hard for humans to understand. Not to mention, they require significant resources to be trained and tested. Attackers can also find ways to bypass these models via adversarial attacks, as it is susceptible to email content that is intentionally altered to evade detection.

\subsubsection*{Hybrid models and ensemble learning}
Researchers have proposed a combination of the aforementioned approaches in the form of hybrid models, that take into account both traditional and deep learning implementations.

\paragraph{Hybrid approach examples}
\begin{itemize}
    \item \textbf{ML and NLP models}
    \begin{itemize}
        \item ML models such as SVM and Random Forest can be combined with TF-IDF (Term Frequency-Inverse Document Frequency) for feature extraction.
    \end{itemize}
    \item \textbf{Ensemble learning}
    \begin{itemize}
        \item Multiple classifiers (both ML and DL) are used and their predictions are accumulated for an improved accuracy, e.g. majority voting ensemble.
        \item Results in a higher accuracy then just singular models.
        \item Complex to interpret and harder to deploy practically.
    \end{itemize}
\end{itemize}

\paragraph{Limitations of hybrid models}
There is a clear trade-off between performance and complexity. The more complex the model, the better the performance and as a result, the requirement for more resources. Additionally, the layers of complexity make it harder to interpret.

\subsubsection*{Summary}
AI-based phishing detection systems have evolved from just traditional ML models to unique deep learning and hybrid approaches. Although this improves their accuracy, subsequent challenges are introduced, such as interpretability, demand for more computational resources, and vulnerability to adversarial attack manipulation. XAI techniques can be a way to address some of these challenges, especially relating to interpretability, by ensuring transparency and trust.\newline

\noindent The next section will dive deeper into limitaitons of current phishing detection systems, leading onto why explainability is an important factor for an optimal phishing detection solution.

\newpage

\subsection*{Limitations of current AI-based approaches}
Although AI-driven phishing detections solutions have greatly improved cybersecurity efforts, but the models used also suffer from many limitations that make it hard to deploy them in real-world settings. Some of these challenges have been briefly explored in the previous section, but these include the black-boxed nature of some models (deep learning in particular), high false positive and negative rates, limitations of the dataset, and vulnerability to semantic-based attacks. This section delves into more detail on these issues.

\subsubsection*{Black-box nature of AI models}
A large proportion of existing AI phishing detection models, specifically deep learning-based systems, are black-boxed, meaning that their decision making processes are obscured from the user. This is problematic for long-term system usage as interpretability isn't taken into much consideration, and affects:

\begin{itemize}
    \item Users and security analysts, as they cannot establish why an email is flagged as phishing.
    \item Regulatory frameworks, such as GDPR, need AI decisions to be interpretable.
    \item AI models need to be trustworthy if organisations need to justify results made by these systems.
\end{itemize}

\noindent Taking the transformer-based models (e.g. BERT, RoBERTa) as an example, they make predictions based on millions of parameters regardless of their high accuracy. It is therefore difficult to decide which features were responsible for the final classification decision.\newline

\noindent An exemplar scenario can be considered. A security team using a deep learning phishing detection model, achieving 95\% accuracy without much reasoning. It's tough to determine whether the decision-making processes were biased by actual revelvant security features or external noise.\newline

\noindent This is important as the inability to understand AI decisions inhibit it from being implemented in sensitive sectors -- financial, healthcare, and legal -- where explainability is part of a compliance requirement (\textit{Regulation EU 2016/679}).

\subsubsection*{Accuracy vs. explainability trade-off}
There is a clear trade-off between accuracy and explainability in phishing detection models. Highly accurate models taper off in their interpretability, but on the other hand, more interpretable models suffer in accuracy. The challenge here is striking a balance and achieving a model that is both reasonable in its accuracy and interpretability.\newline

\noindent For example, a BERT model with a 98\% accuracy but is completely black-boxed. A random forest model with a 90\% accuracy is less black-boxed and it moderately interpretable. Finally, a decision tree model has the least accuracy with 85\% but is the most interpretable. This is an example of the relationship between better performance compared with interpretability.\newline

\noindent Again, organisations may hesitate to deploy AI models if decisions cannot be verified with proper evidence. In some cases even, a more interpretable model with less accuracy is preferable in high-risk sectors to inspire user confidence.

\subsubsection*{False positives and false negatives}
Any AI-driven systems are prone to generating false positives, i.e. legitimate emails incorrectly flagged as phishing, and false negatives, i.e. phishing emails being classed as legitimate. Each have their own cases.

\paragraph{False positives (FPs) -- legitimate emails flagged as phishing}
\begin{itemize}
    \item If important business emails are blocked, it can distrupt typical company operations.
    \item Security analysts can suffer from alert fatigue, and lead to mistaking phishing emails as legitimate in the long-term.
    \item An example is an AI model incorrectly flagging a legitimate email from an unfamliar third party verified by the organisation as phishing.
\end{itemize}

\paragraph{False negatives (FNs) -- phishing emails classed as legitimate}
\begin{itemize}
    \item More dangerous as missed phshing emails can potentially lead to security breaches.
    \item Attacks can exploit this and evade detection by making minor textual changes.
    \item An example might be a phishing email micking a legitimate Microsoft security alert, and detection is bypassed by a small spelling change.
\end{itemize}

\noindent A comparison of multiple phishing detection solutions showed that high-accuracy models can falter in real-world sceenarios. To take a particular example, CNN-based models achieved 96\% accuracy but had a 6\% false negative rate. It goes to show that only a single successful phishing email can result in a major data breach. Security teams must therefore carefully fine-tune AI models to minimise false negatives and have false positives be managable in a practical sense.

\subsubsection*{Dataset challenges}
A phishing detection model's accuracy depends largely on the datasets they were trained on, especially the quality and diversity of the data. But this gives rise to many issues.

\paragraph{Lack of real-world phishing samples}
A lot of existing datasets consist of phishing emails that are outdated and are not reflective of modern techniques. It is common knowledge that attackers contantly evolve, so any models trained on old datasets have a higher chance of failing to detect new methods. This was evident in a 2019 study, which found that a phishing detection model tained on a 2016 dataset has a 30\% lower accuracy when faced with unseen phishing emails utilising new techniques.

\paragraph{Imbalanced datasets}
Most datasets contain much more legitimate emails when compared to phishing emails, such a 95\%-5\% split. A model can therefore be heavily biased and classify many emails as legitimate -- a high false negative rate. Using techniques such as SMOTE (Synthetic Minority Over Sampling) can lead to a more balanced dataset by generating synthetic samples for lesser classes. Rare phishing patterns can be the focus of some models, i.e. anomaly detection models, rather than strict classification.\newline

\noindent An AI model, although being highly accurate, if trained on an imbalanced dataset it can skew results and have a profound failure in real-world contexts. For practicality and effictiveness, automated periodic dataset updates should take place alongside real-time deployment.

\subsubsection*{Adversarial attack vulerabilities}
As mentioned before, AI models are susceptible to carefully crafted phishing emails with the objective of evading detection. This is classed as an adversarial attack.\newline

\noindent Adversarial attacks work by making small modifications to textual components of the phishing email, including URLs, or metadata to circumvent filters proposed by the AI model. For example, homoglyph attacks are commonly used, i.e. using "m\'{i}crosoft.com" instead of "microsoft.com" (note the difference in the letter "i"). It can be showcased by this exemplar study, by which showed that even minor modifications to a phishing email's wording can completely fool deep learning models and hence invoking a false negative.\newline

\noindent There are clear mitigations strategies to address this attack type. Models can specifically be trained on a dataset of purposely manipulated phishing emails, so they can learn how to classifiy these emails accordingly. Furthermore, by using a hybrid AI and rule-based approached accompanied by static phishing indicators can prove to be useful.\newline

\noindent Since phishing attackers are constantly devising new ways to bypass detection systems, it is of utmost importance to continiously make these systems aware on manipulation methods.

\subsubsection*{Summary}
It can be commonly agreed that AI significantly improves phishing detection, however, the current models explored faced the outlined challenges that include interpretability, dataset limitations, adversarial attacks, and false positives/negatives -- limitations which can be addressed by Explainable AI (XAI) with the overarching goal of improving trust, transparency, and real-world versatile deployment.\newline

\noindent In the next section, XAI and subsequently, its techniques, will be examined as to how they can confront the identified challenges.

\newpage

\subsection*{Introduction to Explainable AI (XAI)}

\subsubsection*{What is Explainable AI?}

\subsubsection*{Why is XAI important in phishing detection?}

\newpage

\subsection*{XAI techniques in phishing detection}

\subsubsection*{Model-specific vs. model-agnostic XAI}

\subsubsection*{SHAP (SHapley Additive Explanations)}

\subsubsection*{LIME (Local Interpretable Model-Agnostic Explanations)}

\subsubsection*{Other XAI approaches}

\newpage

\subsection*{Identified research gaps}

\subsubsection*{Lack of comparative studies}

\subsubsection*{Interpretability vs. performance trade-off}

\subsubsection*{Real-world deployment challenges}

\newpage

\subsection*{Project's contribution in addressing research gaps}

\subsubsection*{Developing a transparent phishing model}

\subsubsection*{Comparing SHAP and LIME for phishing email classification}

\subsubsection*{Ensuring real-world applicability}
