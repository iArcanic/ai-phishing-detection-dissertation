# AI Phishing Detection with Explainable AI (XAI)

## Project Overview
This project explores the development and evaluation of AI models for phishing detection, with a focus on integrating Explainable AI (XAI) techniques to provide insights into model decision-making. Two primary models were developed: a Random Forest classifier using TF-IDF features and a fine-tuned DistilBERT transformer model. XAI methods, specifically SHAP for Random Forest and LIME for DistilBERT, were applied to explain their predictions. The project involved preprocessing several public email corpora, training these models, evaluating their performance on both internal and independent test sets, and analysing their explainability.

## Setup Instructions

### 1. Environment
* Python 3.9+ is recommended.
* It's advisable to use a virtual environment (e.g., `venv` or `conda`).
    ```bash
    python -m venv venv
    source venv/bin/activate  # Linux/macOS
    # venv\Scripts\activate    # Windows
    ```

### 2. Install Dependencies
* Install the required Python packages using the provided `requirements.txt` file:
    ```bash
    pip install -r requirements.txt
    ```

### 3. Google Colaboratory
* The notebooks were primarily developed and run in Google Colaboratory.
* **GPU Requirement:** For fine-tuning and running inference with the DistilBERT model (`09_distilbert_model_training_evaluation.ipynb`, `10_evaluate_distilbert_on_independent_sets.ipynb`, `12_xai_distilbert_lime.ipynb`), a GPU runtime is **essential** for reasonable performance. Ensure this is selected in Colab ("Runtime" -> "Change runtime type" -> "GPU").

## Running the Notebooks
The Jupyter Notebooks are designed to be run sequentially, as outputs from earlier notebooks are often inputs for later ones. It is recommended to run them in the following order:

1.  **Data Preprocessing Notebooks (01-05):**
    * `01_enron_eda_preprocess.ipynb`: Processes Enron data for "ham" emails.
    * `02_spamassassin_eda_preprocess.ipynb`: Processes SpamAssassin data for training "spam/phishing" and "ham" test sets.
    * `03_nigerian_fraud_eda_preprocess.ipynb`: Processes Nigerian Fraud corpus for testing.
    * `04_ceas_csv_eda_preprocess.ipynb`: Processes CEAS 08 CSV for training "phishing" emails.
    * `05_nazario_csv_eda_preprocess.ipynb`: Processes Nazario CSV for testing.
    * *Output:* Processed CSV files for each dataset (e.g., `enron_ham_processed.csv`, `ceas_phishing_for_training.csv`, etc.), typically saved to the Colab runtime.

2.  **`06_combine_training_data_and_split.ipynb`:**
    * Loads processed Enron ham and CEAS phishing data.
    * Combines them into a primary training/development corpus.
    * Splits this corpus into `train_corpus.csv`, `validation_corpus.csv`, and `test_corpus.csv`.

3.  **`07_feature_engineering.ipynb`:**
    * Loads `train_corpus.csv`, `validation_corpus.csv`, `test_corpus.csv`.
    * Performs TF-IDF vectorisation for Random Forest.
    * Saves TF-IDF features (`X_*.npz`), labels (`y_*.csv`), and the `tfidf_vectorizer.joblib`.

4.  **`08_model_training_and_evaluation_rf.ipynb`:**
    * Loads TF-IDF features and labels.
    * Trains and tunes the Random Forest model.
    * Evaluates RF on the internal test set.
    * Saves `phishing_random_forest_model.joblib`.

5.  **`09_distilbert_model_training_evaluation.ipynb`:**
    * Loads the *text-based* `train_corpus.csv`, `validation_corpus.csv`, `test_corpus.csv`.
    * Fine-tunes the DistilBERT model.
    * Evaluates DistilBERT on the internal test set.
    * Saves the fine-tuned DistilBERT model and tokenizer (e.g., in `./distilbert_phishing_model/` directory, which should be zipped for sharing via GDrive).

6.  **Evaluation on Independent Test Sets Notebooks:**
    * `10_evaluate_rf_on_independent_sets.ipynb`: Loads the saved RF model, TF-IDF vectoriser, and independent test set CSVs to evaluate RF generalization.
    * `10_evaluate_distilbert_on_independent_sets.ipynb` (or `11_...` if numbered after RF's): Loads the saved DistilBERT model, tokeniser, and independent test set CSVs to evaluate DistilBERT generalisation.

7.  **XAI Notebooks:**
    * `11_xai_rf_shap.ipynb` (or `12_...`): Loads RF model, TF-IDF vectorizer, and test data to generate SHAP explanations.
    * `12_xai_distilbert_lime.ipynb` (or `13_...`): Loads DistilBERT model, tokeniser, and test data to generate LIME explanations.

**Note:** Ensure that files generated by one notebook (and saved to Google Drive if using `gdown` for inter-notebook data passing) are correctly referenced (with updated GDrive File IDs) in subsequent notebooks.

## Expected Outputs
* Processed datasets in CSV format.
* Saved machine learning models (`.joblib` for Random Forest, a directory for DistilBERT).
* Saved TF-IDF vectoriser (`.joblib`).
* Saved numerical features (`.npz`) and labels (`.csv`).
* Performance evaluation metrics and confusion matrices for both models on internal and external test sets.
* SHAP and LIME visualisations and analyses for model explainability.